{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "embedding_function = OpenAIEmbeddings()\n",
    "\n",
    "docs = [\n",
    "    Document(\n",
    "        page_content=\"the dog loves to eat pizza\", metadata={\"source\": \"animal.txt\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"the cat loves to eat lasagna\", metadata={\"source\": \"animal.txt\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "db = Chroma.from_documents(docs, embedding_function)\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "retriever = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'animal.txt'}, page_content='the dog loves to eat pizza'),\n",
       " Document(metadata={'source': 'animal.txt'}, page_content='the cat loves to eat lasagna')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"What exactly?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/6q0d47xn7p70rnjn04w1vvyw0000gn/T/ipykernel_17724/297727499.py:32: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  convo_qa_chain(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What kind of food does the cat like?',\n",
       " 'chat_history': '',\n",
       " 'answer': 'The cat loves to eat lasagna.',\n",
       " 'source_documents': [Document(metadata={'source': 'animal.txt'}, page_content='the cat loves to eat lasagna'),\n",
       "  Document(metadata={'source': 'animal.txt'}, page_content='the dog loves to eat pizza')]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "qa_template = \"\"\"\n",
    "You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer\n",
    "the question. If you don't know the answer, say that you\n",
    "don't know. Use three sentences maximum and keep the\n",
    "answer concise.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "\n",
    "Other context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "qa_prompt = ChatPromptTemplate.from_template(qa_template)\n",
    "\n",
    "convo_qa_chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm,\n",
    "    retriever,\n",
    "    return_source_documents=True,\n",
    "    combine_docs_chain_kwargs={\n",
    "        \"prompt\": qa_prompt,\n",
    "    },\n",
    ")\n",
    "\n",
    "convo_qa_chain(\n",
    "    {\n",
    "        \"question\": \"What kind of food does the cat like?\",\n",
    "        \"chat_history\": \"\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "rephrase_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question, in its original language.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "REPHRASE_TEMPLATE = PromptTemplate.from_template(rephrase_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "rephrase_chain = REPHRASE_TEMPLATE | ChatOpenAI(temperature=0) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is that really what the dog likes to eat?'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rephrase_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"No, really?\",\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"What does the dog like to eat?\"),\n",
    "            AIMessage(content=\"Thuna!\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"\"\"Answer the question based only on the following context:\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "ANSWER_PROMPT = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "retrieval_chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | ANSWER_PROMPT\n",
    "    | ChatOpenAI(temperature=0)\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chain = rephrase_chain | retrieval_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the provided context, the dog loves to eat pizza.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"No, really?\",\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"What does the dog like to eat?\"),\n",
    "            AIMessage(content=\"Thuna!\"),\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat with returning documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_documents = {\"docs\": retriever, \"question\": RunnablePassthrough()}\n",
    "final_inputs = {\n",
    "    \"context\": lambda x: \"\\n\".join(doc.page_content for doc in x[\"docs\"]),\n",
    "    \"question\": lambda x: x[\"question\"],\n",
    "}\n",
    "answer = {\n",
    "    \"answer\": final_inputs | ANSWER_PROMPT | ChatOpenAI(model=\"gpt-4o-mini\") | StrOutputParser(),\n",
    "    \"docs\": lambda x: x[\"docs\"],\n",
    "}\n",
    "\n",
    "final_chain = rephrase_chain | retrieved_documents | answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'answer': 'Yes, according to the context, the dog loves to eat pizza.', 'docs': [Document(metadata={'source': 'animal.txt'}, page_content='the dog loves to eat pizza'), Document(metadata={'source': 'animal.txt'}, page_content='the cat loves to eat lasagna')]}\n"
     ]
    }
   ],
   "source": [
    "result = final_chain.invoke(\n",
    "    {\n",
    "        \"question\": \"No, really?\",\n",
    "        \"chat_history\": [\n",
    "            HumanMessage(content=\"What does the dog like to eat?\"),\n",
    "            AIMessage(content=\"Thuna!\"),\n",
    "        ],\n",
    "    }\n",
    ")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Yes, according to the context, the dog loves to eat pizza.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'animal.txt'}, page_content='the dog loves to eat pizza'),\n",
       " Document(metadata={'source': 'animal.txt'}, page_content='the cat loves to eat lasagna')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"docs\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udemycourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Function Calling\n",
    "\n",
    "The newer OpenAI Function Calling Functionality allows to to define functions which will be passed to the LLM. The LLM\n",
    "will identify the correct function for the request and provide parameters for the function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "def chat(query):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": query}],\n",
    "    )\n",
    "    message = response.choices[0].message.content\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The cost of a pizza salami can vary depending on the size, quality of ingredients, and location of the pizzeria. On average, a medium-sized pizza salami can cost between $10 to $15. However, prices may vary so it is best to check with your local pizzeria for the most accurate pricing.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How much does pizza salami cost?\"\n",
    "message = chat(query)\n",
    "message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make use of Function calling you need:\n",
    "\n",
    "1. A function\n",
    "2. A dictionary which describes the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def get_pizza_info(pizza_name: str):\n",
    "    pizza_info = {\n",
    "        \"name\": pizza_name,\n",
    "        \"price\": \"10.99\",\n",
    "    }\n",
    "    return json.dumps(pizza_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_pizza_info\",\n",
    "        \"description\": \"Get name and price of a pizza of the restaurant\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"pizza_name\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The name of the pizza, e.g. Salami\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"pizza_name\"],\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(query):\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[{\"role\": \"user\", \"content\": query}],\n",
    "        functions=functions, # this is new\n",
    "    )\n",
    "    message = response.choices[0].message\n",
    "    return message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='The capital of France is Paris.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"What is the capital of france?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=None, refusal=None, role='assistant', annotations=[], audio=None, function_call=FunctionCall(arguments='{\"pizza_name\":\"Salami\"}', name='get_pizza_info'), tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "query = \"How much does pizza salami cost?\"\n",
    "message = chat(query)\n",
    "print(message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salami\n",
      "{\"name\": \"Salami\", \"price\": \"10.99\"}\n"
     ]
    }
   ],
   "source": [
    "if message.function_call:\n",
    "    pizza_name = json.loads(message.function_call.arguments).get(\"pizza_name\")\n",
    "    print(pizza_name)\n",
    "    function_response = get_pizza_info(\n",
    "        pizza_name=pizza_name\n",
    "    )\n",
    "    print(function_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-BuhJOzQY6rni09BRmdlQYRVCDEC2w', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='A pizza Salami typically costs $10.99.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None))], created=1752852558, model='gpt-3.5-turbo-0125', object='chat.completion', service_tier='default', system_fingerprint=None, usage=CompletionUsage(completion_tokens=11, prompt_tokens=58, total_tokens=69, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "second_response = openai.chat.completions.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": query},\n",
    "        message,\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": \"get_pizza_info\",\n",
    "            \"content\": function_response,\n",
    "        },\n",
    "    ],\n",
    ")\n",
    "second_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same can be achieved with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains.openai_functions import create_openai_fn_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/6q0d47xn7p70rnjn04w1vvyw0000gn/T/ipykernel_29866/699797286.py:9: LangChainDeprecationWarning: The function `create_openai_fn_chain` was deprecated in LangChain 0.1.1 and will be removed in 1.0. Use :meth:`~create_openai_fn_runnable` instead.\n",
      "  chain = create_openai_fn_chain(functions, llm, prompt, verbose=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
    "\n",
    "template = \"\"\"You are an AI chatbot having a conversation with a human.\n",
    "\n",
    "Human: {human_input}\n",
    "AI: \"\"\"\n",
    "prompt = PromptTemplate(input_variables=[\"human_input\"], template=template)\n",
    "\n",
    "chain = create_openai_fn_chain(functions, llm, prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/9l/6q0d47xn7p70rnjn04w1vvyw0000gn/T/ipykernel_29866/3518985645.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  chain.run(\"How much does pizza salami cost?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an AI chatbot having a conversation with a human.\n",
      "\n",
      "Human: How much does pizza salami cost?\n",
      "AI: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pizza_name': 'Salami'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"How much does pizza salami cost?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use Pydantic Classes instead of JSON Schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class GetPizzaInfo(BaseModel):\n",
    "    \"\"\"Get name and price of a pizza of the restaurant.\"\"\"\n",
    "\n",
    "    pizza_name: str = Field(..., description=\"The name of the pizza, e.g. Salami\")\n",
    "\n",
    "pydantic_classes = [GetPizzaInfo]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_openai_fn_chain(pydantic_classes, llm, prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an AI chatbot having a conversation with a human.\n",
      "\n",
      "Human: How much does pizza salami cost?\n",
      "AI: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GetPizzaInfo(pizza_name='Salami')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"How much does pizza salami cost?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also pass Functions directly.\n",
    "To pass Python function in directly, we'll want to make sure our parameters have type hints, we have a docstring, and we use Google Python style docstrings to describe the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pizza_info(pizza_name: str) -> dict[str, str]:\n",
    "    \"\"\"\n",
    "    Get name and price of a pizza of the restaurant.\n",
    "\n",
    "    Args:\n",
    "        pizza_name: The name of the pizza, e.g. Salami.\n",
    "\n",
    "    Returns:\n",
    "        Dict[str, str]: A dictionary containing the name and price of the pizza.\n",
    "    \"\"\"\n",
    "    pizza_info = {\n",
    "        \"name\": pizza_name,\n",
    "        \"price\": \"10.99\",\n",
    "    }\n",
    "    return pizza_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = create_openai_fn_chain([get_pizza_info], llm, prompt, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are an AI chatbot having a conversation with a human.\n",
      "\n",
      "Human: How much does pizza salami cost?\n",
      "AI: \u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pizza_name': 'Salami'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"How much does pizza salami cost?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "udemycourse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
